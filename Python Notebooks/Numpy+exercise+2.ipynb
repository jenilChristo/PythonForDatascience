{"cells":[{"cell_type":"markdown","metadata":{"id":"1XBw7BkkSt0F"},"source":["# Exercise Background\n","\n","This small application based coding exercise is ment to expose you to the use of the numpy library as well as give you a taste of tasks that you might be needed to perform during machine learning. \n","\n","Usually, machine learning involves working on large data sets. This notebook will walk you through normalising the data and then dividing the data set into smaller subsets. It is recommended that while attempting each of the tasks visit the NumPy library to find the most appropriate function which can help you achieve the desired result. More often than not you will find the functions which you require prewritten in the library. The **numpy library** can be found [here.](https://numpy.org/doc/stable/) \n","\n","Without further ado, the first task is to mean normalise a data set. Mean normalising is a data transformation done to reduce the variations in the data set. For example, consider a data set which has integers between 0 and 10000. That is a lot of variation, and it becomes difficult to build ML algorithms on this data. So mean normalisation is done on such data, after the transformation, the mean of the data will be zero, and standard deviation will be 1.  Even though the actual values of data will change a lot, but the overall variation is still kept intact. If the concept of normalisation feels a bit unclear dont worry all of this will be covered in the future sections of this program. For now, let’s concentrate on the tasks at hand. \n","\n","\n","# Task 1: Mean Normalisation: \n","\n","**Question 1.1** Create a 2D of random integers between 0 and 10,000 (including both 0 and 10,000) with 25000 rows and 15 columns. This will be the dataset you will use in the notebook. "]},{"cell_type":"code","source":["10000/15"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VaYkfMa8VVu9","executionInfo":{"status":"ok","timestamp":1676099845713,"user_tz":-330,"elapsed":607,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"f2271958-d5d1-4700-ba48-3a3b82afc167"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["666.6666666666666"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["help(np.random.random_integers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tsCvxEBFV_fE","executionInfo":{"status":"ok","timestamp":1676099989264,"user_tz":-330,"elapsed":10,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"54cc2322-e146-4a21-a802-b156d305ff24"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on built-in function random_integers:\n","\n","random_integers(...) method of numpy.random.mtrand.RandomState instance\n","    random_integers(low, high=None, size=None)\n","    \n","    Random integers of type `np.int_` between `low` and `high`, inclusive.\n","    \n","    Return random integers of type `np.int_` from the \"discrete uniform\"\n","    distribution in the closed interval [`low`, `high`].  If `high` is\n","    None (the default), then results are from [1, `low`]. The `np.int_`\n","    type translates to the C long integer type and its precision\n","    is platform dependent.\n","    \n","    This function has been deprecated. Use randint instead.\n","    \n","    .. deprecated:: 1.11.0\n","    \n","    Parameters\n","    ----------\n","    low : int\n","        Lowest (signed) integer to be drawn from the distribution (unless\n","        ``high=None``, in which case this parameter is the *highest* such\n","        integer).\n","    high : int, optional\n","        If provided, the largest (signed) integer to be drawn from the\n","        distribution (see above for behavior if ``high=None``).\n","    size : int or tuple of ints, optional\n","        Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n","        ``m * n * k`` samples are drawn.  Default is None, in which case a\n","        single value is returned.\n","    \n","    Returns\n","    -------\n","    out : int or ndarray of ints\n","        `size`-shaped array of random integers from the appropriate\n","        distribution, or a single such random int if `size` not provided.\n","    \n","    See Also\n","    --------\n","    randint : Similar to `random_integers`, only for the half-open\n","        interval [`low`, `high`), and 0 is the lowest value if `high` is\n","        omitted.\n","    \n","    Notes\n","    -----\n","    To sample from N evenly spaced floating-point numbers between a and b,\n","    use::\n","    \n","      a + (b - a) * (np.random.random_integers(N) - 1) / (N - 1.)\n","    \n","    Examples\n","    --------\n","    >>> np.random.random_integers(5)\n","    4 # random\n","    >>> type(np.random.random_integers(5))\n","    <class 'numpy.int64'>\n","    >>> np.random.random_integers(5, size=(3,2))\n","    array([[5, 4], # random\n","           [3, 3],\n","           [4, 5]])\n","    \n","    Choose five random numbers from the set of five evenly-spaced\n","    numbers between 0 and 2.5, inclusive (*i.e.*, from the set\n","    :math:`{0, 5/8, 10/8, 15/8, 20/8}`):\n","    \n","    >>> 2.5 * (np.random.random_integers(5, size=(5,)) - 1) / 4.\n","    array([ 0.625,  1.25 ,  0.625,  0.625,  2.5  ]) # random\n","    \n","    Roll two six sided dice 1000 times and sum the results:\n","    \n","    >>> d1 = np.random.random_integers(1, 6, 1000)\n","    >>> d2 = np.random.random_integers(1, 6, 1000)\n","    >>> dsums = d1 + d2\n","    \n","    Display results as a histogram:\n","    \n","    >>> import matplotlib.pyplot as plt\n","    >>> count, bins, ignored = plt.hist(dsums, 11, density=True)\n","    >>> plt.show()\n","\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HouMb7HQSt0H","executionInfo":{"status":"ok","timestamp":1676100783233,"user_tz":-330,"elapsed":5,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"3bf10eff-a978-4b3d-b392-c5fe840348a8"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-17-8c91f33e52c8>:6: DeprecationWarning: This function is deprecated. Please call randint(0, 10000 + 1) instead\n","  x = np.random.random_integers(low=0, high=10000,size=(25000,15))\n"]},{"output_type":"execute_result","data":{"text/plain":["(25000, 15)"]},"metadata":{},"execution_count":17}],"source":["\n","from os import XATTR_SIZE_MAX\n","# import NumPy into Python\n","import numpy as np\n","\n","# Create a 25000 x 15 ndarray with random integers in the interval [0, 10000].\n","x = np.random.random_integers(low=0, high=10000,size=(25000,15))\n","\n","# print the shape of X\n","x.shape"]},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-12mq5-ZF7B","executionInfo":{"status":"ok","timestamp":1676100794225,"user_tz":-330,"elapsed":3,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"7eec0e48-e46d-473a-ad8a-c324b08e03b6"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[8568, 8156, 7320, ..., 8925,  756, 1458],\n","       [ 768, 3006, 1068, ..., 1453,  231,  500],\n","       [2510, 1713, 5529, ..., 9796, 2163, 3081],\n","       ...,\n","       [5550, 6063, 2320, ..., 4707, 6891, 1502],\n","       [4380,  844, 4468, ..., 6111, 2468, 3675],\n","       [7440, 1464, 4217, ...,  785, 1072,  212]])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llqYpK0aSt0I","executionInfo":{"status":"ok","timestamp":1676100800782,"user_tz":-330,"elapsed":367,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"fef7811f-6d20-4d21-e4d0-6e3e2b1baee4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([8568, 8156, 7320, 5141,  567, 1062, 1825, 1773, 2646, 3857, 2477,\n","        719, 8925,  756, 1458])"]},"metadata":{},"execution_count":20}],"source":["# print the first row of X\n","x[0, :]"]},{"cell_type":"markdown","metadata":{"id":"sH3M_kzjSt0J"},"source":["Now that you created the array we will mean normalize it. The equation for normalisaing the data is given below:\n","\n","$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n","\n","where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. To put it simply, to find the new value of each element, you have to subtract the mean of respective column form that value and divide the result with the standard deviation of that columns. Now the question is, Why are these operations being done column-wise? That is because usually all the procedures in ML are done column-wise. So it will be beneficial for us to develop the habit of thinking about data column-wise.   "]},{"cell_type":"markdown","metadata":{"id":"-XiQzT8MSt0J"},"source":["**Question 1.2** Find the mean and the standard deviation of each of the columns in the dataset. The result will be two 1D arrays with 15 elements each, representing the mean and standard deviation for each of the columns in the dataset.  "]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8JATmCRSt0J","executionInfo":{"status":"ok","timestamp":1676102110603,"user_tz":-330,"elapsed":350,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"5cd4ff40-28df-43a9-b9df-7dd88b9a3443"},"outputs":[{"output_type":"stream","name":"stdout","text":["[4993.36724 5021.52808 5011.8084  4988.22872 4991.45392 5001.738\n"," 4993.825   5001.13148 5002.64684 4997.70424 4992.01484 4992.34448\n"," 5014.85396 5013.34464 4977.57408]\n","[2890.27591031 2886.52501128 2889.83500685 2879.32132191 2884.60041702\n"," 2887.04516314 2880.92550098 2881.44853103 2893.52762969 2884.04337766\n"," 2887.13601496 2882.45392965 2881.07901546 2889.69070118 2888.02465196]\n"]}],"source":["\n","# Average of the values in each column of X\n","ave_cols = np.average(x, axis = 0)\n","\n","# # print ave_cols  \n","print(ave_cols)\n","\n","# # Standard Deviation of the values in each column of X\n","std_cols =  np.std(x, axis= 0)\n","\n","# # print std_cols  \n","print(std_cols)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZDKbaKZgSt0K"},"source":["**Question 1.3** Print the shape of each both the arrays, they should have 15 elements each.  "]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3GJ2hIuiSt0K","executionInfo":{"status":"ok","timestamp":1676102111940,"user_tz":-330,"elapsed":4,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"1ba3a71e-3e96-4b4b-fb3e-9024391f6899"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(15,)"]},"metadata":{},"execution_count":34}],"source":["# Print the shape of ave_cols\n","ave_cols.shape\n","# Print the shape of std_cols\n","std_cols.shape"]},{"cell_type":"markdown","metadata":{"id":"jeXb7OZ5St0K"},"source":["**Question 1.4** Now that you have mean and standard deviation calculated, it is time to apply the transformation to the dataset. \n"," \n","**HINT** The broadcast property of NumPy can make this a lot easier. You can read about it [here](https://numpy.org/doc/stable/user/basics.broadcasting.html).\n","All you have to do is create one row of transformation values and repeat them through all the values."]},{"cell_type":"code","source":["ave_cols"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0yjbeIi3Zxhw","executionInfo":{"status":"ok","timestamp":1676102113784,"user_tz":-330,"elapsed":6,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"37062acb-9e4b-4a62-e4c6-f6c8a714a79f"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([4993.36724, 5021.52808, 5011.8084 , 4988.22872, 4991.45392,\n","       5001.738  , 4993.825  , 5001.13148, 5002.64684, 4997.70424,\n","       4992.01484, 4992.34448, 5014.85396, 5013.34464, 4977.57408])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"stdn-D7jSt0K","executionInfo":{"status":"ok","timestamp":1676102117081,"user_tz":-330,"elapsed":371,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"0976c8b6-8bc6-4c4f-8832-14006e85e4bd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.23677907,  1.08589806,  0.79872781, ...,  1.35718112,\n","        -1.47328731, -1.21867868],\n","       [-1.46192522, -0.69825415, -1.3647175 , ..., -1.23629166,\n","        -1.65496765, -1.5503933 ],\n","       [-0.85921459, -1.14619761,  0.17896925, ...,  1.65949841,\n","        -0.98638399, -0.65670287],\n","       ...,\n","       [ 0.1925881 ,  0.36080474, -0.93147477, ..., -0.1068537 ,\n","         0.64977728, -1.20344336],\n","       [-0.21221754, -1.44725165, -0.18817974, ...,  0.38046372,\n","        -0.88083636, -0.45102596],\n","       [ 0.84650491, -1.23246051, -0.27503591, ..., -1.46814924,\n","        -1.36393305, -1.65011544]])"]},"metadata":{},"execution_count":36}],"source":["# Mean normalize X\n","x_norm = (x-ave_cols)/std_cols\n","\n","x_norm"]},{"cell_type":"markdown","metadata":{"id":"FzkVFMWWSt0L"},"source":["**Question 1.5** If the transformation has been performed correctly, the mean of elements in each column will be approximately 0. Also, the average of the **minimum** value in each column of X_norm and the average of the **maximum** value in each column of X_norm will have almost the same face value with opposite signs. Let’s confirm if the transformation has happened correctly. "]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DxMjIXLeSt0L","executionInfo":{"status":"ok","timestamp":1676102383102,"user_tz":-330,"elapsed":364,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"13858f61-51af-4fde-eb1e-e18f5ae7afb8"},"outputs":[{"output_type":"stream","name":"stdout","text":["-1.1615005253891771e-17\n","-1.7324719815643366\n","1.732817544359596\n"]}],"source":["# Print the average of all the values of X_norm\n","\n","print(np.average(x_norm))\n","# Print the average of the minimum value in each column of X_norm\n","print(np.average( x_norm.min(axis = 0) ) )\n","# Print the average of the maximum value in each column of X_norm\n","print(np.average( x_norm.max(axis = 0) ) )"]},{"cell_type":"code","source":["print(np.mean(x_norm))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v0lNhuLtiykm","executionInfo":{"status":"ok","timestamp":1676103339582,"user_tz":-330,"elapsed":3,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"591d3894-446b-43c3-b489-89f54726971f"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["-1.1615005253891771e-17\n"]}]},{"cell_type":"code","source":[" x_norm.max(axis = 0) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-HpKml2e_yr","executionInfo":{"status":"ok","timestamp":1676102443567,"user_tz":-330,"elapsed":381,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"c172639c-1244-482f-96c8-447a5a5c3091"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.7322335 , 1.72472849, 1.7261164 , 1.74060854, 1.73630498,\n","       1.73127254, 1.73769679, 1.73484567, 1.72707981, 1.73447314,\n","       1.73458581, 1.73728901, 1.73030521, 1.72567097, 1.7390523 ])"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"evcXXJqzSt0L"},"source":["Be mindful that the exact values might not match since the dataset was initialized using the random function. \n","\n","# Data Spliting \n","\n","After data processing, it is a regular practice in ML to split the dataset into three datasets. \n","\n","1. A Training Set\n","2. A Cross Validation Set\n","3. A Test Set\n","\n","The ratios in which the data is split varies a bit from case to case. But the accepted standard 6:2:2 for train, test, and validation respectively. That is 60% for training data and so on. Again why is the data split or what is the signification of these smaller data sets? These questions are better left unanswered for now. \n","The tanks assigned to you is to split the data in the given proportions randomly. \n","For instance, if the data set had ten elements, this is how you would do it. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zL_X6yVPSt0M","outputId":"3f9eaa93-c5d1-4e8a-d625-31d936b4c51d"},"outputs":[{"data":{"text/plain":["array([8, 3, 7, 5, 2, 6, 1, 9, 0, 4])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# We create a random permutation of integers 0 to 9\n","np.random.permutation(10)"]},{"cell_type":"markdown","metadata":{"id":"KbfZ1lFgSt0M"},"source":["1. training set = 8,3,7,5,2,6\n","2. Cross Validation Set = 1,9\n","3. Test Set = 0,4"]},{"cell_type":"markdown","metadata":{"id":"FYJAfi1_St0M"},"source":["**Question 2.1** Similarly, create a 1D array representing the indexes of the rows in the dataset X_norm. U can use the   `np.random.permutation()` function for randomising the indexes. "]},{"cell_type":"code","execution_count":51,"metadata":{"id":"KymJBwMtSt0M","executionInfo":{"status":"ok","timestamp":1676102804679,"user_tz":-330,"elapsed":349,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}}},"outputs":[],"source":["# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n","\n","row_indices = np.random.permutation(np.arange(0,25000))"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_LLj1kDSt0M","executionInfo":{"status":"ok","timestamp":1676102810089,"user_tz":-330,"elapsed":600,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"fffb4e52-3922-4692-93d5-296c29b19a36"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25000,)"]},"metadata":{},"execution_count":52}],"source":["# Print the shape of row_indices\n","row_indices.shape"]},{"cell_type":"markdown","metadata":{"id":"-LWedR2ASt0N"},"source":["**Question 2.2** Split the row indexes in the needed proportions. You can use the slicing methods you have learnt in this session to make the job easier.  "]},{"cell_type":"code","execution_count":64,"metadata":{"id":"fNJKaLtnSt0N","executionInfo":{"status":"ok","timestamp":1676103124145,"user_tz":-330,"elapsed":607,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}}},"outputs":[],"source":["# Make any necessary calculations.\n","# You can save your calculations into variables to use later.\n","train = row_indices[:15000]\n","test = row_indices[15000:20000]\n","val  = row_indices[20000:  ]"]},{"cell_type":"code","source":["val"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epYJQefQhTao","executionInfo":{"status":"ok","timestamp":1676103125738,"user_tz":-330,"elapsed":4,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"0b8e7e09-544a-41cf-bc9d-2145ed00051b"},"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([15447,   659, 23439, ..., 12782,  7019, 15500])"]},"metadata":{},"execution_count":65}]},{"cell_type":"markdown","metadata":{"id":"AH8FUDaQSt0N"},"source":["**Question 2.3** Now make use of the indexes that you made to split the data also similarly once the data is split print the shape of each of the smaller data sets. `X_train` should have 15000 rows and 15 columns. `X_test` should have 5000 rows and 15 columns. `X_val` should have 5000 rows and 15 columns. "]},{"cell_type":"code","execution_count":66,"metadata":{"id":"hIyzvRI7St0N","executionInfo":{"status":"ok","timestamp":1676103139498,"user_tz":-330,"elapsed":339,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}}},"outputs":[],"source":["# Create a Training Set\n","x_train = x_norm[train]\n","\n","# Create a Cross Validation Set\n","x_val = x_norm[val]\n","\n","# Create a Test Set\n","x_test = x_norm[test]"]},{"cell_type":"code","source":["x_val"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"stK5sPcihQNA","executionInfo":{"status":"ok","timestamp":1676103142980,"user_tz":-330,"elapsed":374,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"32656823-349b-4bc9-8785-a37ac6b84523"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.98351605, -0.45297653, -1.10138066, ...,  0.32944117,\n","         0.08224249, -1.38176593],\n","       [-0.16862308,  0.83888825, -0.873686  , ..., -1.6875115 ,\n","        -1.5726059 , -0.17367375],\n","       [ 0.71329964,  1.59238943,  0.96240498, ..., -1.72499745,\n","        -0.11328017, -0.82256018],\n","       ...,\n","       [-0.91526461, -1.08453177, -1.68895746, ...,  0.16075437,\n","        -1.68645891,  0.55104305],\n","       [ 0.787687  , -1.67659316, -1.16436004, ..., -0.14399257,\n","        -0.49359768,  0.12029881],\n","       [ 0.69876815,  0.04901115, -1.22111068, ..., -0.16655356,\n","        -0.82615923,  1.44230968]])"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9dre4IlDSt0N","executionInfo":{"status":"ok","timestamp":1676107804366,"user_tz":-330,"elapsed":379,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"4bdda28d-5904-4ec4-8881-eb0058134309"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000, 15)"]},"metadata":{},"execution_count":70}],"source":["# Print the shape of X_train\n","x_train.shape\n","\n","# Print the shape of X_crossVal\n","x_val.shape\n","\n","# Print the shape of X_test\n","x_test.shape"]},{"cell_type":"code","source":["a = np.array([1,2,3,4,5,6,7,8])\n","a.reshape(2,2,2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgWvKYxuz2rN","executionInfo":{"status":"ok","timestamp":1676108011927,"user_tz":-330,"elapsed":376,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"0c47d324-7bab-4014-9260-7609826d1fba"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[1, 2],\n","        [3, 4]],\n","\n","       [[5, 6],\n","        [7, 8]]])"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["a.reshape(1,1,-1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YcNeD-5A0pW1","executionInfo":{"status":"ok","timestamp":1676108033786,"user_tz":-330,"elapsed":356,"user":{"displayName":"jenil christo","userId":"10070565132340199789"}},"outputId":"1baabd2b-686a-4a5e-efaa-0253ec1b2250"},"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[1, 2, 3, 4, 5, 6, 7, 8]]])"]},"metadata":{},"execution_count":75}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}